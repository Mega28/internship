{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20f3eab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing required libraries\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import NoSuchElementException, ElementNotInteractableException"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb516cb",
   "metadata": {},
   "source": [
    "\n",
    "1.Scrape the details of most viewed videos on YouTube from Wikipedia:\n",
    "\n",
    "Url= https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos\n",
    "\n",
    "You need to find following details:\n",
    "\n",
    "A) Rank\n",
    "\n",
    "B) Name\n",
    "\n",
    "C) Artist\n",
    "\n",
    "D) Upload date\n",
    "\n",
    "E) Views\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f64bf32",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MEGANATHAN\\AppData\\Local\\Temp\\ipykernel_17580\\2809156455.py:2: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver=webdriver.Chrome(\"C:\\anancoda\\Drivers\\chromedriver.exe\")  #r converts string to raw string\n"
     ]
    },
    {
     "ename": "WebDriverException",
     "evalue": "Message: 'chromedriver.exe' executable needs to be in PATH. Please see https://chromedriver.chromium.org/home\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32mC:\\anancoda\\lib\\site-packages\\selenium\\webdriver\\common\\service.py:71\u001b[0m, in \u001b[0;36mService.start\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     70\u001b[0m     cmd\u001b[38;5;241m.\u001b[39mextend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_line_args())\n\u001b[1;32m---> 71\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess \u001b[38;5;241m=\u001b[39m \u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcmd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     72\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43mclose_fds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msystem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m!=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mWindows\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43mstdout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     74\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43mstderr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     75\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43mstdin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mPIPE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     76\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43mcreationflags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreationflags\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n",
      "File \u001b[1;32mC:\\anancoda\\lib\\subprocess.py:951\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[1;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask)\u001b[0m\n\u001b[0;32m    948\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mTextIOWrapper(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr,\n\u001b[0;32m    949\u001b[0m                     encoding\u001b[38;5;241m=\u001b[39mencoding, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[1;32m--> 951\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecutable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreexec_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclose_fds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    952\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mpass_fds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcwd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    953\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mstartupinfo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreationflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshell\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    954\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mp2cread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp2cwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    955\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mc2pread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc2pwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    956\u001b[0m \u001b[43m                        \u001b[49m\u001b[43merrread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    957\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mrestore_signals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    958\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mgid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mumask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    959\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mstart_new_session\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    960\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m    961\u001b[0m     \u001b[38;5;66;03m# Cleanup if the child failed starting.\u001b[39;00m\n",
      "File \u001b[1;32mC:\\anancoda\\lib\\subprocess.py:1420\u001b[0m, in \u001b[0;36mPopen._execute_child\u001b[1;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, unused_restore_signals, unused_gid, unused_gids, unused_uid, unused_umask, unused_start_new_session)\u001b[0m\n\u001b[0;32m   1419\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1420\u001b[0m     hp, ht, pid, tid \u001b[38;5;241m=\u001b[39m \u001b[43m_winapi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCreateProcess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexecutable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1421\u001b[0m \u001b[43m                             \u001b[49m\u001b[38;5;66;43;03m# no special security\u001b[39;49;00m\n\u001b[0;32m   1422\u001b[0m \u001b[43m                             \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1423\u001b[0m \u001b[43m                             \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mclose_fds\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1424\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mcreationflags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1425\u001b[0m \u001b[43m                             \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1426\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mcwd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1427\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mstartupinfo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1428\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m   1429\u001b[0m     \u001b[38;5;66;03m# Child is launched. Close the parent's copy of those pipe\u001b[39;00m\n\u001b[0;32m   1430\u001b[0m     \u001b[38;5;66;03m# handles that only the child should have open.  You need\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1433\u001b[0m     \u001b[38;5;66;03m# pipe will not close when the child process exits and the\u001b[39;00m\n\u001b[0;32m   1434\u001b[0m     \u001b[38;5;66;03m# ReadFile will hang.\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] The system cannot find the file specified",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mWebDriverException\u001b[0m                        Traceback (most recent call last)",
      "Input \u001b[1;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#Connect to web driver\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m driver\u001b[38;5;241m=\u001b[39m\u001b[43mwebdriver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mChrome\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC:\u001b[39;49m\u001b[38;5;130;43;01m\\a\u001b[39;49;00m\u001b[38;5;124;43mnancoda\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mDrivers\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mchromedriver.exe\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\anancoda\\lib\\site-packages\\selenium\\webdriver\\chrome\\webdriver.py:70\u001b[0m, in \u001b[0;36mWebDriver.__init__\u001b[1;34m(self, executable_path, port, options, service_args, desired_capabilities, service_log_path, chrome_options, service, keep_alive)\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m service:\n\u001b[0;32m     68\u001b[0m     service \u001b[38;5;241m=\u001b[39m Service(executable_path, port, service_args, service_log_path)\n\u001b[1;32m---> 70\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mWebDriver\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mDesiredCapabilities\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCHROME\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbrowserName\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgoog\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     71\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mport\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     72\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mservice_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdesired_capabilities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mservice_log_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeep_alive\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\anancoda\\lib\\site-packages\\selenium\\webdriver\\chromium\\webdriver.py:89\u001b[0m, in \u001b[0;36mChromiumDriver.__init__\u001b[1;34m(self, browser_name, vendor_prefix, port, options, service_args, desired_capabilities, service_log_path, service, keep_alive)\u001b[0m\n\u001b[0;32m     86\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mservice cannot be None\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     88\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mservice \u001b[38;5;241m=\u001b[39m service\n\u001b[1;32m---> 89\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mservice\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     92\u001b[0m     RemoteWebDriver\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m     93\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m     94\u001b[0m         command_executor\u001b[38;5;241m=\u001b[39mChromiumRemoteConnection(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     97\u001b[0m             keep_alive\u001b[38;5;241m=\u001b[39mkeep_alive, ignore_proxy\u001b[38;5;241m=\u001b[39m_ignore_proxy),\n\u001b[0;32m     98\u001b[0m         options\u001b[38;5;241m=\u001b[39moptions)\n",
      "File \u001b[1;32mC:\\anancoda\\lib\\site-packages\\selenium\\webdriver\\common\\service.py:81\u001b[0m, in \u001b[0;36mService.start\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m     80\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m err\u001b[38;5;241m.\u001b[39merrno \u001b[38;5;241m==\u001b[39m errno\u001b[38;5;241m.\u001b[39mENOENT:\n\u001b[1;32m---> 81\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m WebDriverException(\n\u001b[0;32m     82\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m executable needs to be in PATH. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (\n\u001b[0;32m     83\u001b[0m                 os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpath), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstart_error_message)\n\u001b[0;32m     84\u001b[0m         )\n\u001b[0;32m     85\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m err\u001b[38;5;241m.\u001b[39merrno \u001b[38;5;241m==\u001b[39m errno\u001b[38;5;241m.\u001b[39mEACCES:\n\u001b[0;32m     86\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m WebDriverException(\n\u001b[0;32m     87\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m executable may have wrong permissions. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (\n\u001b[0;32m     88\u001b[0m                 os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpath), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstart_error_message)\n\u001b[0;32m     89\u001b[0m         )\n",
      "\u001b[1;31mWebDriverException\u001b[0m: Message: 'chromedriver.exe' executable needs to be in PATH. Please see https://chromedriver.chromium.org/home\n"
     ]
    }
   ],
   "source": [
    "#Connect to web driver\n",
    "driver=webdriver.Chrome(\"C:\\anancoda\\Drivers\\chromedriver.exe\")  #r converts string to raw string\n",
    "#If not r, we can use executable_path = \"C:/path name\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9538b1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting the website to driver\n",
    "driver.get('https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos')\n",
    "\n",
    "#When we run this line, automatically the webpage will be opened"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd3a0f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the empty lists to store the scraped data\n",
    "Rank=[]\n",
    "Name=[]\n",
    "Artist=[]\n",
    "Views=[]\n",
    "Upload_Date=[]\n",
    "\n",
    "#As we need only the first 30 details, we will iterate only for first 30 data\n",
    "#Scrapping the details of the Rank of the video\n",
    "rank=driver.find_elements_by_xpath(\"//table[@class='wikitable sortable jquery-tablesorter']/tbody/tr/td[1]\")\n",
    "for i in rank[:30]:\n",
    "    Rank.append(i.text)\n",
    "    \n",
    "#Scrapping the details of the video name\n",
    "video=driver.find_elements_by_xpath(\"//table[@class='wikitable sortable jquery-tablesorter']/tbody/tr/td[2]\")\n",
    "for i in video[:30]:\n",
    "    Name.append(i.text)\n",
    "    \n",
    "#Scrapping the details of the Artist name\n",
    "artist=driver.find_elements_by_xpath(\"//table[@class='wikitable sortable jquery-tablesorter']/tbody/tr/td[3]\")\n",
    "for i in artist[:30]:\n",
    "    Artist.append(i.text)\n",
    "    \n",
    "#Scrapping the details of the views information\n",
    "views=driver.find_elements_by_xpath(\"//table[@class='wikitable sortable jquery-tablesorter']/tbody/tr/td[4]\")\n",
    "for i in views[:30]:\n",
    "    Views.append(i.text)\n",
    "    \n",
    "#Scrapping the details of the upload date\n",
    "date=driver.find_elements_by_xpath(\"//table[@class='wikitable sortable jquery-tablesorter']/tbody/tr/td[5]\")\n",
    "for i in date[:30]:\n",
    "    Upload_Date.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296066da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a dataframe for storing the scraped data\n",
    "Yt_data=pd.DataFrame({})\n",
    "Yt_data['Rank']=Rank\n",
    "Yt_data['Video Name']=Name\n",
    "Yt_data['Artist']=Artist\n",
    "Yt_data['Views(Billions)']=Views\n",
    "Yt_data['Upload Date']=Upload_Date\n",
    "Yt_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb82dda8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing the stray numbers from videoname\n",
    "new=Yt_data[\"Video Name\"].str.split(\"[\", n = 1, expand = True) \n",
    "new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0841ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping the column with stray numbers\n",
    "Yt_data.drop(columns=['Video Name'],axis=1,inplace=True)\n",
    "\n",
    "#Inserting the name column\n",
    "Yt_data.insert(1,\"Video Name\",new[0])\n",
    "\n",
    "#Checking the data after removing the stray numbers\n",
    "Yt_data  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129e4d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Closing the driver\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf45206",
   "metadata": {},
   "source": [
    "\n",
    "2.Scrape the details team India’s international fixtures from bcci.tv.\n",
    "\n",
    "Url = https://www.bcci.tv/\n",
    "\n",
    "You need to find following details:\n",
    "\n",
    "A) Match title (I.e. 1st ODI)\n",
    "\n",
    "B) Series\n",
    "\n",
    "C) Place\n",
    "\n",
    "D) Date\n",
    "\n",
    "E) Time\n",
    "\n",
    "Note: - From bcci.tv home page you have reach to the international fixture page through code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00516be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connect to web driver\n",
    "driver=webdriver.Chrome(r\"D://chromedriver.exe\")  #r converts string to raw string\n",
    "#If not r, we can use executable_path = \"C:/path name\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945073cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting the website to driver\n",
    "driver.get('https://www.bcci.tv/')\n",
    "\n",
    "#When we run this line, automatically the webpage will be openedv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c86109a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clicking international fixture section\n",
    "international=driver.find_element_by_xpath(\"//ul[@class='navigation__list showMoreEnabled']/li[1]/div[2]/div/ul/li[1]/a\")\n",
    "driver.get(international.get_attribute('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fddc932",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating empty lists for storing the scrapped data\n",
    "Match=[]\n",
    "Series=[]\n",
    "Place=[]\n",
    "Date=[]\n",
    "Time=[]\n",
    "\n",
    "#Scrapping the data having the match name\n",
    "name=driver.find_elements_by_xpath(\"//strong[@class='fixture__name fixture__name--with-margin']\")\n",
    "for i in name:\n",
    "    Match.append(i.text)\n",
    "\n",
    "#Scrapping the data having the series name\n",
    "series=driver.find_elements_by_xpath(\"//div[@class='fixture__format-strip']/span[2]\")\n",
    "for i in series:\n",
    "    Series.append(i.text)\n",
    "    \n",
    "#Scrapping the data having the place of match\n",
    "place=driver.find_elements_by_xpath(\"//p[@class='fixture__additional-info']/span\")\n",
    "for i in place:\n",
    "    Place.append(i.text)\n",
    "    \n",
    "#Scrapping the data having the match date\n",
    "date=driver.find_elements_by_xpath(\"//div[@class='fixture__datetime desktop-only']/div/span\")  #Only date\n",
    "month=driver.find_elements_by_xpath(\"//div[@class='fixture__datetime desktop-only']/div/div/span[1]\")  #Month\n",
    "for i in range(len(date)):\n",
    "    Date.append(date[i].text + month[i].text)  #Appending date and month texts together\n",
    "    \n",
    "#Scrapping the data having match time\n",
    "time=driver.find_elements_by_xpath(\"//div[@class='fixture__full-date']/div/span[2]\")\n",
    "for i in time:\n",
    "    Time.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0a3e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a Dataframe for the scrapped data\n",
    "fixtures=pd.DataFrame({})\n",
    "fixtures['Match name']=Match\n",
    "fixtures['Series']=Series\n",
    "fixtures['Place']=Place\n",
    "fixtures['Date']=Date\n",
    "fixtures['Time']=Time\n",
    "fixtures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418d32bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Closing the driver\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a83268",
   "metadata": {},
   "source": [
    "\n",
    "3.Scrape the details of selenium exception from guru99.com.\n",
    "\n",
    "Url = https://www.guru99.com/\n",
    "\n",
    "You need to find following details:\n",
    "\n",
    "A) Name\n",
    "\n",
    "B) Description\n",
    "\n",
    "Note: - From guru99 home page you have to reach to selenium exception handling page through code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aabff56",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connect to web driver\n",
    "driver=webdriver.Chrome(r\"D://chromedriver.exe\")  #r converts string to raw string\n",
    "#If not r, we can use executable_path = \"C:/path name\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc9c3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting the website to driver\n",
    "driver.get('https://www.guru99.com/')\n",
    "\n",
    "#When we run this line, automatically the webpage will be opened"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d44aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clicking on the selenium tutorial page \n",
    "driver.find_element_by_xpath(\"//div[@class='srch']/span[8]/a\").click()\n",
    "\n",
    "#Clicking on the selenium exception tutorial page\n",
    "driver.find_element_by_xpath(\"//table[@class='table']/tbody/tr[34]/td/a\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c91857e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the empty lists to store the scraped data\n",
    "Name=[]\n",
    "Description=[]\n",
    "\n",
    "#Scrapping the data having exception names\n",
    "name=driver.find_elements_by_xpath(\"//table[@class='table table-striped']/tbody/tr/td[1]\")\n",
    "for i in name:\n",
    "    Name.append(i.text)\n",
    "    \n",
    "#Scrapping the data having the description details  \n",
    "desc=driver.find_elements_by_xpath(\"//table[@class='table table-striped']/tbody/tr/td[2]\")\n",
    "for i in desc:\n",
    "    Description.append(i.text)\n",
    "    \n",
    "#Checking the length of the data scrapped\n",
    "print(len(Name),len(Description))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee2b18e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a dataframe for the scrapped data\n",
    "guru99=pd.DataFrame({})\n",
    "guru99['Exception Name']=Name[1:]\n",
    "guru99['Description']=Description[1:]\n",
    "guru99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7134ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Closing the driver\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "641d2638",
   "metadata": {},
   "source": [
    "\n",
    "4.Scrape the details of State-wise GDP of India from statisticstime.com.\n",
    "\n",
    "Url = http://statisticstimes.com/\n",
    "\n",
    "You have to find following details:\n",
    "\n",
    "A) Rank\n",
    "\n",
    "B) State\n",
    "\n",
    "C) GSDP(19-20)\n",
    "\n",
    "D) GSDP(18-19)\n",
    "\n",
    "E) Share(18-19)\n",
    "\n",
    "F) GDP($ billion)\n",
    "\n",
    "Note: - From statisticstimes home page you have to reach to economy page through code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8cf2198",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connect to web driver\n",
    "driver=webdriver.Chrome(r\"D://chromedriver.exe\")  #r converts string to raw string\n",
    "#If not r, we can use executable_path = \"C:/path name\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8c11c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connect to web driver\n",
    "driver=webdriver.Chrome(r\"D://chromedriver.exe\")  #r converts string to raw string\n",
    "#If not r, we can use executable_path = \"C:/path name\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc388e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clicking the economy tab and then India option\n",
    "economy=driver.find_element_by_xpath(\"//div[@class='navbar']/div[2]/div/a[3]\")\n",
    "try:\n",
    "    economy.click()\n",
    "except ElementNotInteractableException:\n",
    "    driver.get(economy.get_attribute('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb2bc79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clicking on GDP of Indian states option\n",
    "gdp=driver.find_element_by_xpath(\"//div[@style='float:left;background-color:seashell;width:400px;height:800px;']/ul/li[1]\")\n",
    "try:\n",
    "    gdp.click()\n",
    "except ElementNotInteractableException:\n",
    "    driver.get(gdp.get_attribute('href'))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82de1ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating empty lists for storing the scrapped data\n",
    "Rank=[]\n",
    "State=[]\n",
    "GSDP19_20=[]\n",
    "GSDP18_19=[]\n",
    "Share18_19=[]\n",
    "GDP=[]\n",
    "\n",
    "#Scrapping the data having rank of the states\n",
    "rank=driver.find_elements_by_xpath(\"//table[@class='display dataTable']/tbody/tr/td[1]\")\n",
    "for i in rank:\n",
    "    Rank.append(i.text)\n",
    "    \n",
    "#Scrapping the data having State name\n",
    "state=driver.find_elements_by_xpath(\"//table[@class='display dataTable']/tbody/tr/td[2]\")\n",
    "for i in state:\n",
    "    State.append(i.text)\n",
    "    \n",
    "#Scrapping the data having GSDP 19-20 data\n",
    "for i in driver.find_elements_by_xpath(\"//table[@class='display dataTable']/tbody/tr/td[3]\"):\n",
    "    GSDP19_20.append(i.text)\n",
    "    \n",
    "#Scrapping the data having GSDP 18-19 data\n",
    "for i in driver.find_elements_by_xpath(\"//table[@class='display dataTable']/tbody/tr/td[4]\"):\n",
    "    GSDP18_19.append(i.text)\n",
    "    \n",
    "#Scrapping the data having Share 18-19 data\n",
    "for i in driver.find_elements_by_xpath(\"//table[@class='display dataTable']/tbody/tr/td[5]\"):\n",
    "    Share18_19.append(i.text)\n",
    "    \n",
    "#Scrapping the data having GDP billions data\n",
    "for i in driver.find_elements_by_xpath(\"//table[@class='display dataTable']/tbody/tr/td[6]\"):\n",
    "    GDP.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9189ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a dataframe for the scrapped data\n",
    "GDP_data=pd.DataFrame({'Rank':Rank,'State':State,'GSDP(19-20)':GSDP19_20,'GSDP(18-19)':GSDP18_19,'Share(18-19)':Share18_19,\n",
    "                      'GDP($ billion)':GDP})\n",
    "GDP_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594ecd2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Closing the driver\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede99785",
   "metadata": {},
   "source": [
    "\n",
    "5.Scrape the details of trending repositories on Github.com.\n",
    "\n",
    "Url = https://github.com/\n",
    "\n",
    "You have to find the following details:\n",
    "\n",
    "A) Repository title\n",
    "\n",
    "B) Repository description\n",
    "\n",
    "C) Contributors count\n",
    "\n",
    "D) Language used\n",
    "\n",
    "Note: - From the home page you have to click on the trending option from Explore menu through code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60ff362",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connect to web driver\n",
    "driver=webdriver.Chrome(r\"D://chromedriver.exe\")  #r converts string to raw string\n",
    "#If not r, we can use executable_path = \"C:/path name\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca18405",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting the website to driver\n",
    "driver.get('https://github.com/')\n",
    "\n",
    "#When we run this line, automatically the webpage will be opened"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94dee587",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clicking explore tab and trending option using exception\n",
    "trending=driver.find_element_by_xpath(\"/html/body/div[1]/header/div/div[2]/nav/ul/li[4]/details/div/ul[2]/li[3]/a\")\n",
    "try:\n",
    "    trending.click()\n",
    "except ElementNotInteractableException as e:\n",
    "    driver.get(trending.get_attribute('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb8fdf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating empty lists for storing the scrapped data\n",
    "rep_title=[]\n",
    "rep_desc=[]\n",
    "Count=[]\n",
    "Lang=[]\n",
    "\n",
    "#Scrapping the data having the repository title\n",
    "title=driver.find_elements_by_xpath(\"//h1[@class='h3 lh-condensed']/a\")\n",
    "for i in title:\n",
    "    rep_title.append(i.text)\n",
    "    \n",
    "#Scrapping the data having the repository description\n",
    "desc=driver.find_elements_by_xpath(\"//p[@class='col-9 color-text-secondary my-1 pr-4']\")\n",
    "for i in desc:\n",
    "    rep_desc.append(i.text)\n",
    "    \n",
    "#Scrapping the data having the contributors count\n",
    "count=driver.find_elements_by_xpath(\"//div[@class='f6 color-text-secondary mt-2']/a[2]\")\n",
    "for i in count:\n",
    "    Count.append(i.text)\n",
    "    \n",
    "#Scrapping the data having the language used \n",
    "lang=driver.find_elements_by_xpath(\"//span[@class='d-inline-block ml-0 mr-3']\")\n",
    "for i in lang:\n",
    "    if i.text is None:\n",
    "        Lang.append('Not Available')\n",
    "    else:\n",
    "        Lang.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc643820",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking out the length of scrapped data\n",
    "print(len(rep_title),len(rep_desc),len(Count),len(Lang))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065e5e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a dataframe for the scrapped data\n",
    "github=pd.DataFrame({})\n",
    "github['Repository title']=rep_title[:21]\n",
    "github['Description']=rep_desc[:21]\n",
    "github['Contributors count']=Count[:21]\n",
    "github['Language used']=Lang\n",
    "github"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6de9267",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Closing the driver\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b277f4b1",
   "metadata": {},
   "source": [
    "\n",
    "6.Scrape the details of top 100 songs on billiboard.com.\n",
    "\n",
    "Url = https://www.billboard.com/\n",
    "\n",
    "You have to find the following details:\n",
    "\n",
    "A) Song name\n",
    "\n",
    "B) Artist name\n",
    "\n",
    "C) Last week rank\n",
    "\n",
    "D) Peak rank\n",
    "\n",
    "E) Weeks on board\n",
    "\n",
    "Note: - From the home page you have to click on the charts option then hot 100-page link through code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3210097",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connect to web driver\n",
    "driver=webdriver.Chrome(r\"D://chromedriver.exe\")  #r converts string to raw string\n",
    "#If not r, we can use executable_path = \"C:/path name\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "975c0bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting the website to driver\n",
    "driver.get('https://www.billboard.com/')\n",
    "\n",
    "#When we run this line, automatically the webpage will be opened"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a199a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clicking charts and then hot100 option\n",
    "hot_100=driver.find_element_by_xpath(\"//nav[@class='header__subnav bg--light']/ul/li[3]/a\")\n",
    "try:\n",
    "    hot_100.click()\n",
    "except ElementNotInteractableException:\n",
    "    driver.get(hot_100.get_attribute('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b96e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating empty lists for storing the scrapped data\n",
    "Song=[]\n",
    "Artist=[]\n",
    "Lastweek=[]\n",
    "Peak=[]\n",
    "Weeks_on_board=[]\n",
    "\n",
    "#Scrapping the data having the song name\n",
    "song=driver.find_elements_by_xpath(\"//span[@class='chart-element__information__song text--truncate color--primary']\")\n",
    "for i in song:\n",
    "    Song.append(i.text)\n",
    "    \n",
    "#Scrapping the data having the artist name\n",
    "artist=driver.find_elements_by_xpath(\"//span[@class='chart-element__information__artist text--truncate color--secondary']\")\n",
    "for i in artist:\n",
    "    Artist.append(i.text)\n",
    "    \n",
    "#Scrapping the data having the last week rank\n",
    "last_week=driver.find_elements_by_xpath(\"//div[@class='chart-element__meta text--center color--secondary text--last']\")\n",
    "for i in last_week:\n",
    "    if i.text is None:\n",
    "        Lastweek.append('-')\n",
    "    else:\n",
    "        Lastweek.append(i.text)\n",
    "        \n",
    "#Scrapping the data having the peak rank\n",
    "peak=driver.find_elements_by_xpath(\"//div[@class='chart-element__meta text--center color--secondary text--peak']\")\n",
    "for i in peak:\n",
    "    if i.text is None:\n",
    "        Peak.append('-')\n",
    "    else:\n",
    "        Peak.append(i.text)\n",
    "        \n",
    "#Scrapping the data having weeks on board data\n",
    "weeks=driver.find_elements_by_xpath(\"//div[@class='chart-element__meta text--center color--secondary text--week']\")\n",
    "for i in weeks:\n",
    "    if i.text is None:\n",
    "        Weeks_on_board.append('-')\n",
    "    else:\n",
    "        Weeks_on_board.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f0c0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a dataframe for the scrapped data\n",
    "billboard=pd.DataFrame({'Song':Song,'Artist':Artist,'Last week Rank':Lastweek,'Peak Rank':Peak,'Weeks on board':Weeks_on_board})\n",
    "billboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f305fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Closing the driver\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de3eabf",
   "metadata": {},
   "source": [
    "\n",
    "7.Scrape the details of Data science recruiters from naukri.com.\n",
    "\n",
    "Url = https://www.naukri.com/\n",
    "\n",
    "You have to find the following details:\n",
    "\n",
    "A) Name\n",
    "\n",
    "B) Designation\n",
    "\n",
    "C) Company\n",
    "\n",
    "D) Skills they hire for\n",
    "\n",
    "E) Location\n",
    "\n",
    "Note: - From naukri.com homepage click on the recruiters option and the on the search pane type Data science and click on search. All this should be done through code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7165534a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connect to web driver\n",
    "driver=webdriver.Chrome(r\"D://chromedriver.exe\")  #r converts string to raw string\n",
    "#If not r, we can use executable_path = \"C:/path name\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20373a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting the website to driver\n",
    "driver.get('https://www.naukri.com/')\n",
    "\n",
    "#When we run this line, automatically the webpage will be opened"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e11c3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clicking the recruiters option\n",
    "recruit=driver.find_element_by_xpath(\"//ul[@class='midSec menu']/li[2]/a\")\n",
    "driver.get(recruit.get_attribute('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230d55c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding the required elements from the search bars of job \n",
    "search_job=driver.find_element_by_xpath(\"//input[@class='sugInp']\")\n",
    "search_job.send_keys('Data science')  #Sending the keyword\n",
    "\n",
    "#Clicking the button for searching the keyword\n",
    "driver.find_element_by_xpath(\"//button[@class='fl qsbSrch blueBtn']\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9720d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating empty lists for storing the scrapped data\n",
    "Name=[]\n",
    "Designation=[]\n",
    "Company=[]\n",
    "Skills=[]\n",
    "Location=[]\n",
    "\n",
    "#Scrapping the data having the recruiter's name\n",
    "name=driver.find_elements_by_xpath(\"//span[@class='fl ellipsis']\")\n",
    "for i in name:\n",
    "    Name.append(i.text)\n",
    "    \n",
    "#Scrapping the data having the recruiter's designation\n",
    "desc=driver.find_elements_by_xpath(\"//span[@class='ellipsis clr']\")\n",
    "for i in desc:\n",
    "    Designation.append(i.text)\n",
    "    \n",
    "#Scrapping the data having company name\n",
    "company=driver.find_elements_by_xpath(\"//p[@class='highlightable']/a[2]\")\n",
    "for i in company:\n",
    "    Company.append(i.text)\n",
    "    \n",
    "#Scrapping the data having the skillset details\n",
    "skills=driver.find_elements_by_xpath(\"//div[@class='hireSec highlightable']\")\n",
    "for i in skills:\n",
    "    Skills.append(i.text)\n",
    "    \n",
    "#Scrapping the data having the location details\n",
    "location=driver.find_elements_by_xpath(\"//small[@class='ellipsis']\")\n",
    "for i in location:\n",
    "    Location.append(i.text) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0632444f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking the length of the scrapped data\n",
    "print(len(Name),len(Designation),len(Company),len(Skills),len(Location))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3f5f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a dataframe for the scrapped data\n",
    "naukri=pd.DataFrame({})\n",
    "naukri['Name']=Name[:48]\n",
    "naukri['Designation']=Designation[:48]\n",
    "naukri['Company']=Company[:48]\n",
    "naukri['Skills']=Skills[:48]\n",
    "naukri['Location']=Location\n",
    "naukri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9352567c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Closing the driver\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b43428f5",
   "metadata": {},
   "source": [
    "\n",
    "8.Scrape the details of Highest selling novels.\n",
    "\n",
    "Url = https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare/\n",
    "\n",
    "You have to find the following details:\n",
    "\n",
    "A) Book name\n",
    "\n",
    "B) Author name\n",
    "\n",
    "C) Volumes sold\n",
    "\n",
    "D) Publisher\n",
    "\n",
    "E) Genre\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed59f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connect to web driver\n",
    "driver=webdriver.Chrome(r\"D://chromedriver.exe\")  #r converts string to raw string\n",
    "#If not r, we can use executable_path = \"C:/path name\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8dde81",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting the website to driver\n",
    "driver.get('https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare/')\n",
    "\n",
    "#When we run this line, automatically the webpage will be opened"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6448e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating empty lists to store the scrapped data\n",
    "Book=[]\n",
    "Author=[]\n",
    "Volume=[]\n",
    "Publisher=[]\n",
    "Genre=[]\n",
    "\n",
    "#Scrapping the data having the book name\n",
    "book=driver.find_elements_by_xpath(\"//table[@class='in-article sortable']/tbody/tr/td[2]\")\n",
    "for i in book:\n",
    "    Book.append(i.text)\n",
    "    \n",
    "#Scrapping the data having the author name\n",
    "author=driver.find_elements_by_xpath(\"//table[@class='in-article sortable']/tbody/tr/td[3]\")\n",
    "for i in author:\n",
    "    Author.append(i.text)\n",
    "    \n",
    "#Scrapping the data having the volumes sold details\n",
    "volume=driver.find_elements_by_xpath(\"//table[@class='in-article sortable']/tbody/tr/td[4]\")\n",
    "for i in volume:\n",
    "    Volume.append(i.text)\n",
    "\n",
    "#Scrapping the data having publisher details\n",
    "publisher=driver.find_elements_by_xpath(\"//table[@class='in-article sortable']/tbody/tr/td[5]\")\n",
    "for i in publisher:\n",
    "    Publisher.append(i.text)\n",
    "    \n",
    "#Scrapping the data having genre details \n",
    "genre=driver.find_elements_by_xpath(\"//table[@class='in-article sortable']/tbody/tr/td[6]\")\n",
    "for i in genre:\n",
    "    Genre.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213b4daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a dataframe for the scrapped data\n",
    "novels=pd.DataFrame({})\n",
    "novels['Book']=Book\n",
    "novels['Author']=Author\n",
    "novels['Volumes sold']=Volume\n",
    "novels['Publisher']=Publisher\n",
    "novels['Genre']=Genre\n",
    "novels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15cdd11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Closing the driver\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d2fc3be",
   "metadata": {},
   "source": [
    "\n",
    "9.Scrape the details most watched tv series of all time from imdb.com.\n",
    "\n",
    "Url = https://www.imdb.com/list/ls095964455/\n",
    "\n",
    "You have to find the following details:\n",
    "\n",
    "A) Name\n",
    "\n",
    "B) Year span\n",
    "\n",
    "C) Genre\n",
    "\n",
    "D) Run time\n",
    "\n",
    "E) Ratings\n",
    "\n",
    "F) Votes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd8c6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connect to web driver\n",
    "driver=webdriver.Chrome(r\"D://chromedriver.exe\")  #r converts string to raw string\n",
    "#If not r, we can use executable_path = \"C:/path name\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c760f8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting the website to driver\n",
    "driver.get('https://www.imdb.com/list/ls095964455/')\n",
    "\n",
    "#When we run this line, automatically the webpage will be opened"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edfa4804",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating empty lists for storing the scrapped data\n",
    "Name=[]\n",
    "Year=[]\n",
    "Genre=[]\n",
    "Runtime=[]\n",
    "Rating=[]\n",
    "Vote=[]\n",
    "\n",
    "#Scrapping the data having the series name\n",
    "name=driver.find_elements_by_xpath(\"//h3[@class='lister-item-header']/a\")\n",
    "for i in name:\n",
    "    Name.append(i.text)\n",
    "    \n",
    "#Scrapping the data having the year span details\n",
    "year=driver.find_elements_by_xpath(\"//span[@class='lister-item-year text-muted unbold']\")\n",
    "for i in year:\n",
    "    Year.append(i.text)\n",
    "    \n",
    "#Scrapping the data having the genre details\n",
    "genre=driver.find_elements_by_xpath(\"//span[@class='genre']\")\n",
    "for i in genre:\n",
    "    Genre.append(i.text)\n",
    "    \n",
    "#Scrapping the data having the runtime details\n",
    "runtime=driver.find_elements_by_xpath(\"//span[@class='runtime']\")\n",
    "for i in runtime:\n",
    "    Runtime.append(i.text)\n",
    "    \n",
    "#Scrapping the data having rating details\n",
    "rating=driver.find_elements_by_xpath(\"//div[@class='ipl-rating-star small']\")\n",
    "for i in rating:\n",
    "    Rating.append(i.text)\n",
    "    \n",
    "#Scrapping the data having the votes details\n",
    "votes=driver.find_elements_by_xpath(\"//span[@name='nv']\")\n",
    "for i in votes:\n",
    "    Vote.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88db65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a dataframe for the scrapped data\n",
    "IMDB=pd.DataFrame({'Name':Name,'Year span':Year,'Genre':Genre,'Runtime':Runtime,'Rating':Rating,'Votes':Vote})\n",
    "IMDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2ed81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Closing the driver\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0cf1f12",
   "metadata": {},
   "source": [
    "\n",
    "10.Details of Datasets from UCI machine learning repositories.\n",
    "\n",
    "Url = https://archive.ics.uci.edu/\n",
    "\n",
    "You have to find the following details:\n",
    "\n",
    "A) Dataset name\n",
    "\n",
    "B) Data type\n",
    "\n",
    "C) Task\n",
    "\n",
    "D) Attribute type\n",
    "\n",
    "E) No of instances\n",
    "\n",
    "F) No of attribute\n",
    "\n",
    "G) Year\n",
    "\n",
    "Note: - from the home page you have to go to the Show All Dataset page through code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9bfa42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connect to web driver\n",
    "driver=webdriver.Chrome(r\"D://chromedriver.exe\")  #r converts string to raw string\n",
    "#If not r, we can use executable_path = \"C:/path name\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4b96c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting the website to driver\n",
    "driver.get('https://archive.ics.uci.edu/')\n",
    "#When we run this line, automatically the webpage will be opened"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60712c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clicking on view all datasets link\n",
    "datasets=driver.find_element_by_xpath(\"/html/body/table[1]/tbody/tr/td[2]/span[2]/a/font/b\")\n",
    "try:\n",
    "    datasets.click()\n",
    "except ElementNotInteractableException:\n",
    "    driver.get(datasets.get_attribute('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32cfbf5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating empty lists for storing the scrapped data\n",
    "Name=[]\n",
    "Type=[]\n",
    "Task=[]\n",
    "Attribute=[]\n",
    "No_of_Instance=[]\n",
    "No_of_Attribute=[]\n",
    "Year=[]\n",
    "\n",
    "#Scrapping the data having dataset name\n",
    "try:\n",
    "    names=driver.find_elements_by_xpath(\"/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr/td[1]/table/tbody/tr/td[2]/p/b/a\")\n",
    "    for i in names:\n",
    "        Name.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Name.append('-')\n",
    "    \n",
    "#Scrapping the data having data type\n",
    "try:\n",
    "    types=driver.find_elements_by_xpath(\"/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr/td[2]\")\n",
    "    for i in types[1:]:\n",
    "        Type.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Type.append('-')\n",
    "    \n",
    "#Scrapping the data having default task\n",
    "try:\n",
    "    task=driver.find_elements_by_xpath(\"/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr/td[3]\")\n",
    "    for i in task[1:]:\n",
    "        Task.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Task.append('-')\n",
    "        \n",
    "#Scrapping the data having attribute types\n",
    "try:\n",
    "    attribute=driver.find_elements_by_xpath(\"/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr/td[4]\")\n",
    "    for i in attribute[1:]:\n",
    "        Attribute.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Attribute.append('-')\n",
    "        \n",
    "#Scrapping the data having no of instances\n",
    "try:\n",
    "    instance=driver.find_elements_by_xpath(\"/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr/td[5]\")\n",
    "    for i in instance[1:]:\n",
    "        No_of_Instance.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    No_of_Instance.append('-')\n",
    "        \n",
    "#Scrapping the data having no of attributes\n",
    "try:\n",
    "    attribute_no=driver.find_elements_by_xpath(\"/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr/td[6]\")\n",
    "    for i in attribute_no[1:]:\n",
    "        No_of_Attribute.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    No_of_Attribute.append('-')\n",
    "        \n",
    "#Scrapping the data having the year details\n",
    "try:\n",
    "    year=driver.find_elements_by_xpath(\"/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr/td[7]\")\n",
    "    for i in year[1:]:\n",
    "        Year.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Year.append('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce547410",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the dataframe\n",
    "df=pd.DataFrame({\"Name\":Name,\"Data types\":Type,\"Default Task\":Task,\"Attribute types\":Attribute, \n",
    "                 \"No of instances\":No_of_Instance,\"No of atrributes\":No_of_Attribute,\"Year\":Year})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095d1090",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Closing the driver\n",
    "driver.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
